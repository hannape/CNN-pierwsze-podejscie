{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_scorer_not_working.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/CNN-pierwsze-podejscie/blob/master/cnn_grid_with_scorer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hT7H1AgFX8wi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class Histories(keras.callbacks.Callback):\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.aucs = []\n",
        "\t\tself.losses = []\n",
        "\n",
        "\tdef on_train_end(self, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_begin(self, epoch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tself.losses.append(logs.get('loss'))\n",
        "\t\ty_pred = self.model.predict(self.validation_data[0])\n",
        "\t\tself.aucs.append(roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\ta = (roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\tprint(\" AUC_on_val: %f \" % a)\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_begin(self, batch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_end(self, batch, logs={}):    return\n",
        "  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUs78Pg157U2",
        "colab_type": "code",
        "outputId": "031f5265-d4db-438f-f2e6-fb24ee70ebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import  make_scorer\n",
        "from sklearn.metrics import log_loss\n",
        "K.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import functools\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# num_classes = 2\n",
        "X_train = numpy.load('drive/My Drive/X_train.npy')\n",
        "y_train = numpy.load('drive/My Drive/y_train.npy')\n",
        "X_test = numpy.load('drive/My Drive/X_test.npy')\n",
        "y_test = numpy.load('drive/My Drive/y_test.npy')\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 60, 87).astype('float32')\n",
        "#X_val = X_val.reshape(X_val.shape[0], 1, 60, 87).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 60, 87).astype('float32')\n",
        "\n",
        "input_shape = (1, 60, 87)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(30581, 1, 60, 87) (30581,)\n",
            "(10793, 1, 60, 87) (10793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXXL6keoH1l4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(Conv2D(filters, kernel_size))\n",
        "    #model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    #for layer_size in dense_layer_sizes:\n",
        "    model.add(Dense(dense_layer_sizes))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VKGfhskBZVkD",
        "colab_type": "code",
        "outputId": "c38b9c9d-e92e-4ed2-89fb-570b808d2c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "c_w = { 0:0.02, 1:0.98}\n",
        "index = ['r%d' % x for x in range(len(y_train))]\n",
        "a = [c_w[class_label] for class_label in y_train]\n",
        "sample_weight_frame = pd.DataFrame(a, index = index)\n",
        "score_params = {\"sample_weight\": sample_weight_frame}\n",
        "print(sample_weight_frame[0:5])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0\n",
            "r0  0.98\n",
            "r1  0.02\n",
            "r2  0.02\n",
            "r3  0.02\n",
            "r4  0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yFE3UDjTMJ9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "\n",
        "### SCORERS\n",
        "import functools\n",
        "def my_score(y_true, y_pred, sample_weight): \n",
        "  return log_loss(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1), normalize=True)\n",
        "    \n",
        "def my_score2(sample_weight):  # <----------------wersja 2, implementowana w ten sposób by potem przy compile(loss=...) nie trzeba było podawać 3 argumentów (bo nie wiem jak nawet gdybym chciała)\n",
        "  def loss_2_args(y_true, y_pred):  \n",
        "      return log_loss(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1), normalize=True)   \n",
        "  return loss_2_args\n",
        "\n",
        "my_scorer = make_scorer(my_score,\n",
        "                          greater_is_better=False, \n",
        "                          needs_threshold=False,\n",
        "                          **score_params)\n",
        "\n",
        "my_scorer2 = make_scorer(my_score2,\n",
        "                          greater_is_better=False, \n",
        "                          needs_threshold=False,\n",
        "                          **score_params)\n",
        "\n",
        "my_loss = functools.partial(my_score, sample_weight=sample_weight_frame)  # za: https://github.com/keras-team/keras/issues/2115\n",
        "\n",
        "# z https://github.com/keras-team/keras/issues/2115\n",
        "from functools import partial, update_wrapper\n",
        "\n",
        "def wrapped_partial(func, *args, **kwargs):\n",
        "\tpartial_func = partial(func, *args, **kwargs)\n",
        "\tupdate_wrapper(partial_func, func)\n",
        "\treturn partial_func\n",
        "\n",
        "def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "\treturn loss\n",
        "\n",
        "custom_loss = wrapped_partial(binary_crossentropy_weigted, class_weights=np.array([0.02, 0.98]))\n",
        "\n",
        "## AUC METRIC\n",
        "\n",
        "def as_keras_metric(method):\n",
        "    import functools\n",
        "    from keras import backend as K\n",
        "    import tensorflow as tf\n",
        "    @functools.wraps(method)\n",
        "    def wrapper(self, args, **kwargs):\n",
        "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
        "        value, update_op = method(self, args, **kwargs)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([update_op]):\n",
        "            value = tf.identity(value)\n",
        "        return value\n",
        "    return wrapper\n",
        "  \n",
        "auc_roc = as_keras_metric(tf.metrics.auc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhBPDEWTvxMO",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow.python.ops import clip_ops\n",
        "from tensorflow.python.framework import dtypes as dtypes_module\n",
        "from tensorflow.python.util.tf_export import tf_export\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "@tf_export('keras.backend.dtype')\n",
        "def dtype(x):\n",
        "  return x.dtype.base_dtype.name\n",
        "\n",
        "_EPSILON = 1e-7\n",
        "def epsilon():\n",
        "  return _EPSILON\n",
        "\n",
        "def _to_tensor(x, dtype):\n",
        "  return ops.convert_to_tensor(x, dtype=dtype)\n",
        "\n",
        "def binary_crossentropy(target, output, from_logits=False):\n",
        "  if not from_logits:\n",
        "    # transform back to logits\n",
        "   \n",
        "    #epsilon_ = tensorflow.convert_to_tensor(epsilon(), np.float32)\n",
        "    #output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
        "    output = math_ops.log(output / (1 - output))\n",
        "  return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDsoy0g8VlB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_weight = sample_weight_frame\n",
        "def mean_squared_error2(y_true, y_pred):   ## taka działa w compile\n",
        "  return K.mean(K.square(y_pred*2 - y_true), axis=-1)\n",
        "\n",
        "def loss_2_args_new(y_true, y_pred):    ## a czemu taka nie?\n",
        "  return log_loss(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1), normalize=True)\n",
        "\n",
        "def make_model_modified(dense_layer_sizes,filters, kernel_size,pool_size):\n",
        "\n",
        "    #dense_layer_sizes= 128\n",
        "    #filters = 20\n",
        "    #kernel_size = [3,3]\n",
        "    #pool_size = [2,2]\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss=custom_loss,#'binary_crossentropy',#loss_2_args(y_true, y_pred)'',#loss='binary_crossentropy'\n",
        "                  # co tu powinno wejść? o samo co do scoring w GridSearchCv? chyba nie: https://stackoverflow.com/questions/40572743/scikit-learn-grid-search-own-scoring-object-syntax\n",
        "                  # my_score2(sample_weight = sample_weight_frame), <------------------- nie umiem zrobić by działał tutaj. Która funkcja? my_score czy my_scorer ?\n",
        "                  # my_score2(sample_weight_frame) ---->  https://stackoverflow.com/questions/46858016/keras-custom-loss-function-to-pass-arguments-other-than-y-true-and-y-pred\n",
        "                  # my_loss ---------------------------->też nie chodzi a chyba powinien, coś z formatem nie tak.  ERROR: 'Tensor' object has no attribute 'values'\n",
        "                  # inne źródło: https://github.com/keras-team/keras/issues/2115\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy',metrics=auc_roc])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17fUBh-ClyNT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "## spr czemu się wykrzacza\n",
        "model = make_model_modified() #(128,20,3,2)\n",
        "hist = model.fit(X_train, y_train, epochs=15, batch_size=64, callbacks=[histories]) # validation_data=(X_val, y_val), class_weight = class_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmUkJOKTM_Wo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def larger_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(20, (3,3), input_shape=(1, 60, 87), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  #model.compile(loss=roc_auc_score_loss, optimizer='adam', metrics=['accuracy','mae'])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YQJvxfSN1Iy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "my_classifier = KerasClassifier(make_model_modified)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [128],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [15],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     # 'class_weight': [{ 0:0.02, 1:0.98}],  <------------------------------- może w ten sposób? Ale t też tylko w grid searchu\n",
        "                                     'batch_size': [32, 64]}, \n",
        "                         scoring=my_scorer, n_jobs=1, refit=True, cv = 3)  ## SCORING ZMIENIONY na my_scorer (inne, np: 'roc_auc')\n",
        "\n",
        "##https://stackoverflow.com/questions/49581104/sklearn-gridsearchcv-not-using-sample-weight-in-score-function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC9TynBWTR0E",
        "colab_type": "code",
        "outputId": "49faa72b-6cc1-4b5b-cc50-f5fde6dffed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3895
        }
      },
      "cell_type": "code",
      "source": [
        "#histories = Histories()\n",
        "\n",
        "#from sklearn.utils import class_weight\n",
        "#class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "#print(class_weights)\n",
        "#c_w2= [0.02 , 0.98]\n",
        "#c_w = { 0:0.02, 1:0.98}\n",
        "#print(c_w)\n",
        "\n",
        "y_frame = pd.DataFrame(y_train, index=index)\n",
        "grid_result = validator.fit(X_train, y_frame) #, class_weight = c_w)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 21s 1ms/step - loss: 0.0906 - acc: 0.9881\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.0862 - acc: 0.9893\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.0862 - acc: 0.9893\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.0702 - acc: 0.9893\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 11s 528us/step - loss: 0.0320 - acc: 0.9893\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 11s 525us/step - loss: 0.0320 - acc: 0.9893\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.0313 - acc: 0.9893\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 11s 525us/step - loss: 0.0316 - acc: 0.9893\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0313 - acc: 0.9893\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.0309 - acc: 0.9894\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 11s 531us/step - loss: 0.0307 - acc: 0.9894\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0305 - acc: 0.9894\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 11s 523us/step - loss: 0.0309 - acc: 0.9894\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 11s 522us/step - loss: 0.0306 - acc: 0.9894\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0303 - acc: 0.9895\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 21s 1ms/step - loss: 0.0596 - acc: 0.9786\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0531 - acc: 0.9793\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 11s 525us/step - loss: 0.0526 - acc: 0.9793\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0526 - acc: 0.9793\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.0519 - acc: 0.9793\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 11s 522us/step - loss: 0.0516 - acc: 0.9793\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 11s 522us/step - loss: 0.0518 - acc: 0.9794\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.0518 - acc: 0.9793\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0507 - acc: 0.9794\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 11s 531us/step - loss: 0.0505 - acc: 0.9794\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.0504 - acc: 0.9794\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0486 - acc: 0.9796\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 11s 523us/step - loss: 0.0468 - acc: 0.9803\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0417 - acc: 0.9822\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0380 - acc: 0.9838\n",
            "Epoch 1/15\n",
            "20388/20388 [==============================] - 22s 1ms/step - loss: 0.0619 - acc: 0.9765\n",
            "Epoch 2/15\n",
            "20388/20388 [==============================] - 11s 522us/step - loss: 0.0569 - acc: 0.9765\n",
            "Epoch 3/15\n",
            "20388/20388 [==============================] - 11s 527us/step - loss: 0.0570 - acc: 0.9765\n",
            "Epoch 4/15\n",
            "20388/20388 [==============================] - 11s 523us/step - loss: 0.0563 - acc: 0.9765\n",
            "Epoch 5/15\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0556 - acc: 0.9765\n",
            "Epoch 6/15\n",
            "20388/20388 [==============================] - 11s 533us/step - loss: 0.0561 - acc: 0.9766\n",
            "Epoch 7/15\n",
            "20388/20388 [==============================] - 11s 524us/step - loss: 0.0549 - acc: 0.9766\n",
            "Epoch 8/15\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0557 - acc: 0.9768\n",
            "Epoch 9/15\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0563 - acc: 0.9768\n",
            "Epoch 10/15\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0536 - acc: 0.9776\n",
            "Epoch 11/15\n",
            "20388/20388 [==============================] - 11s 530us/step - loss: 0.0444 - acc: 0.9807\n",
            "Epoch 12/15\n",
            "20388/20388 [==============================] - 11s 527us/step - loss: 0.0385 - acc: 0.9835\n",
            "Epoch 13/15\n",
            "20388/20388 [==============================] - 11s 526us/step - loss: 0.0433 - acc: 0.9842\n",
            "Epoch 14/15\n",
            "20388/20388 [==============================] - 11s 524us/step - loss: 0.0378 - acc: 0.9856\n",
            "Epoch 15/15\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0342 - acc: 0.9867\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 18s 871us/step - loss: 0.0443 - acc: 0.9873\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0321 - acc: 0.9893\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0309 - acc: 0.9893\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 7s 326us/step - loss: 0.0316 - acc: 0.9893\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0306 - acc: 0.9893\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 7s 324us/step - loss: 0.0309 - acc: 0.9893\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 7s 327us/step - loss: 0.0310 - acc: 0.9893\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 7s 323us/step - loss: 0.0304 - acc: 0.9893\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 7s 324us/step - loss: 0.0306 - acc: 0.9893\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 7s 321us/step - loss: 0.0303 - acc: 0.9893\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 6s 319us/step - loss: 0.0303 - acc: 0.9893\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 7s 319us/step - loss: 0.0308 - acc: 0.9893\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 7s 320us/step - loss: 0.0301 - acc: 0.9893\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 6s 318us/step - loss: 0.0301 - acc: 0.9895\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 6s 318us/step - loss: 0.0297 - acc: 0.9895\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 18s 878us/step - loss: 0.0652 - acc: 0.9789\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 7s 324us/step - loss: 0.0530 - acc: 0.9793\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 7s 324us/step - loss: 0.0535 - acc: 0.9793\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0531 - acc: 0.9793\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0531 - acc: 0.9793\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 7s 323us/step - loss: 0.0518 - acc: 0.9793\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 7s 321us/step - loss: 0.0522 - acc: 0.9793\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 7s 322us/step - loss: 0.0515 - acc: 0.9793\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 7s 320us/step - loss: 0.0522 - acc: 0.9793\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 7s 325us/step - loss: 0.0518 - acc: 0.9794\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 7s 324us/step - loss: 0.0519 - acc: 0.9794\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 7s 320us/step - loss: 0.0514 - acc: 0.9794\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 7s 320us/step - loss: 0.0512 - acc: 0.9793\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 7s 321us/step - loss: 0.0504 - acc: 0.9794\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 7s 320us/step - loss: 0.0502 - acc: 0.9794\n",
            "Epoch 1/15\n",
            "20388/20388 [==============================] - 18s 886us/step - loss: 0.0674 - acc: 0.9759\n",
            "Epoch 2/15\n",
            "20388/20388 [==============================] - 7s 321us/step - loss: 0.0575 - acc: 0.9765\n",
            "Epoch 3/15\n",
            "20388/20388 [==============================] - 7s 320us/step - loss: 0.0570 - acc: 0.9765\n",
            "Epoch 4/15\n",
            "20388/20388 [==============================] - 7s 321us/step - loss: 0.0573 - acc: 0.9765\n",
            "Epoch 5/15\n",
            "20388/20388 [==============================] - 7s 320us/step - loss: 0.0566 - acc: 0.9765\n",
            "Epoch 6/15\n",
            "20388/20388 [==============================] - 7s 320us/step - loss: 0.0564 - acc: 0.9765\n",
            "Epoch 7/15\n",
            "20388/20388 [==============================] - 7s 321us/step - loss: 0.0564 - acc: 0.9766\n",
            "Epoch 8/15\n",
            "20388/20388 [==============================] - 7s 321us/step - loss: 0.0558 - acc: 0.9765\n",
            "Epoch 9/15\n",
            "20388/20388 [==============================] - 7s 320us/step - loss: 0.0561 - acc: 0.9767\n",
            "Epoch 10/15\n",
            "20388/20388 [==============================] - 7s 319us/step - loss: 0.0554 - acc: 0.9767\n",
            "Epoch 11/15\n",
            "20388/20388 [==============================] - 6s 318us/step - loss: 0.0555 - acc: 0.9768\n",
            "Epoch 12/15\n",
            "20388/20388 [==============================] - 6s 318us/step - loss: 0.0547 - acc: 0.9771\n",
            "Epoch 13/15\n",
            "20388/20388 [==============================] - 6s 319us/step - loss: 0.0535 - acc: 0.9772\n",
            "Epoch 14/15\n",
            "20388/20388 [==============================] - 6s 318us/step - loss: 0.0529 - acc: 0.9775\n",
            "Epoch 15/15\n",
            "20388/20388 [==============================] - 6s 319us/step - loss: 0.0538 - acc: 0.9786\n",
            "Epoch 1/15\n",
            "30581/30581 [==============================] - 28s 907us/step - loss: 0.0542 - acc: 0.9808\n",
            "Epoch 2/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0485 - acc: 0.9817\n",
            "Epoch 3/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0475 - acc: 0.9817\n",
            "Epoch 4/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0475 - acc: 0.9817\n",
            "Epoch 5/15\n",
            "30581/30581 [==============================] - 16s 524us/step - loss: 0.0467 - acc: 0.9817\n",
            "Epoch 6/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0469 - acc: 0.9817\n",
            "Epoch 7/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0468 - acc: 0.9817\n",
            "Epoch 8/15\n",
            "30581/30581 [==============================] - 16s 526us/step - loss: 0.0465 - acc: 0.9817\n",
            "Epoch 9/15\n",
            "30581/30581 [==============================] - 16s 534us/step - loss: 0.0465 - acc: 0.9818\n",
            "Epoch 10/15\n",
            "30581/30581 [==============================] - 16s 525us/step - loss: 0.0464 - acc: 0.9818\n",
            "Epoch 11/15\n",
            "30581/30581 [==============================] - 16s 520us/step - loss: 0.0454 - acc: 0.9819\n",
            "Epoch 12/15\n",
            "30581/30581 [==============================] - 16s 522us/step - loss: 0.0439 - acc: 0.9822\n",
            "Epoch 13/15\n",
            "30581/30581 [==============================] - 16s 522us/step - loss: 0.0415 - acc: 0.9833\n",
            "Epoch 14/15\n",
            "30581/30581 [==============================] - 16s 523us/step - loss: 0.0374 - acc: 0.9848\n",
            "Epoch 15/15\n",
            "30581/30581 [==============================] - 16s 523us/step - loss: 0.0345 - acc: 0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aOXKJUC-bjnb",
        "colab_type": "code",
        "outputId": "552930ea-aebb-4219-8a36-ce5fe53c72fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)\n",
        "\n",
        "best_model = validator.best_estimator_.model\n",
        "metric_names = best_model.metrics_names\n",
        "metric_values = best_model.evaluate(X_test, y_test)\n",
        "for metric, value in zip(metric_names, metric_values):\n",
        "  print(metric, ': ', value)\n",
        "  \n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "10793/10793 [==============================] - 7s 664us/step\n",
            "loss :  0.08307418281665505\n",
            "acc :  0.9551561197072176\n",
            "-13.162782 (6.270563) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-14.786941 (5.286675) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bb6y2EBKUMZ5",
        "colab_type": "code",
        "outputId": "9cb89f5f-2de0-4d93-d5bf-00c7df1f2b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate AUC of final model on a test set\n",
        "probs = best_model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "#probs = probs[:, 1]\n",
        "y_test2 = numpy.load('drive/My Drive/y_test.npy')  # osobno, bo inny wymiar\n",
        "\n",
        "auc = roc_auc_score(y_test2, probs)\n",
        "print('AUC: %.3f' % auc)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, probs)\n",
        "# plot no skill\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr, tpr, marker='.')\n",
        "# show the plot\n",
        "plt.title('ROC curve for test set')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTEREpBCGMBERkUIYwkRERAr5P/zr3ZBqfzNdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f18b309d128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}