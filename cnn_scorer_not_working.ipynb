{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_scorer_not_working.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/CNN-pierwsze-podejscie/blob/master/cnn_scorer_not_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hT7H1AgFX8wi",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class Histories(keras.callbacks.Callback):\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.aucs = []\n",
        "\t\tself.losses = []\n",
        "\n",
        "\tdef on_train_end(self, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_begin(self, epoch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tself.losses.append(logs.get('loss'))\n",
        "\t\ty_pred = self.model.predict(self.validation_data[0])\n",
        "\t\tself.aucs.append(roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\ta = (roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\tprint(\" AUC_on_val: %f \" % a)\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_begin(self, batch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_end(self, batch, logs={}):    return\n",
        "  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUs78Pg157U2",
        "colab_type": "code",
        "outputId": "32267dc5-6aac-468c-cc2f-8435c37fd39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import  make_scorer\n",
        "from sklearn.metrics import log_loss\n",
        "K.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# num_classes = 2\n",
        "X_train = numpy.load('drive/My Drive/X_train.npy')\n",
        "y_train = numpy.load('drive/My Drive/y_train.npy')\n",
        "X_test = numpy.load('drive/My Drive/X_test.npy')\n",
        "y_test = numpy.load('drive/My Drive/y_test.npy')\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 60, 87).astype('float32')\n",
        "#X_val = X_val.reshape(X_val.shape[0], 1, 60, 87).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 60, 87).astype('float32')\n",
        "\n",
        "input_shape = (1, 60, 87)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30581, 1, 60, 87) (30581,)\n",
            "(10793, 1, 60, 87) (10793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXXL6keoH1l4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(Conv2D(filters, kernel_size))\n",
        "    #model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    #for layer_size in dense_layer_sizes:\n",
        "    model.add(Dense(dense_layer_sizes))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VKGfhskBZVkD",
        "colab_type": "code",
        "outputId": "d47506bc-7907-4f5b-e790-62944ccbd5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "c_w = { 0:0.02, 1:0.98}\n",
        "index = ['r%d' % x for x in range(len(y_train))]\n",
        "a = [c_w[class_label] for class_label in y_train]\n",
        "sample_weight_frame = pd.DataFrame(a, index = index)\n",
        "score_params = {\"sample_weight\": sample_weight_frame}\n",
        "print(sample_weight_frame[0:5])"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0\n",
            "r0  0.98\n",
            "r1  0.02\n",
            "r2  0.02\n",
            "r3  0.02\n",
            "r4  0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yFE3UDjTMJ9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "import functools\n",
        "def my_score(y_true, y_pred, sample_weight): \n",
        "  return log_loss(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1), normalize=True)\n",
        "    \n",
        "def my_score2(sample_weight):  # <--------------------------------wersja 2, implementowana w ten sposób by potem przy compile(loss=...) nie trzeba było podawać 3 argumentów (bo nie wiem jak nawet gdybym chciała)\n",
        "  def loss_2_args(y_true, y_pred):  \n",
        "      return log_loss(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1), normalize=True)   \n",
        "\n",
        "  return loss_2_args\n",
        "\n",
        "my_scorer = make_scorer(my_score,\n",
        "                          greater_is_better=False, \n",
        "                          needs_threshold=False,\n",
        "                          **score_params)\n",
        "\n",
        "my_scorer2 = make_scorer(my_score2,\n",
        "                          greater_is_better=False, \n",
        "                          needs_threshold=False,\n",
        "                          **score_params)\n",
        "\n",
        "my_loss = functools.partial(my_score, sample_weight=sample_weight_frame)  # za: https://github.com/keras-team/keras/issues/2115"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhBPDEWTvxMO",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow.python.ops import clip_ops\n",
        "from tensorflow.python.framework import dtypes as dtypes_module\n",
        "from tensorflow.python.util.tf_export import tf_export\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "@tf_export('keras.backend.dtype')\n",
        "def dtype(x):\n",
        "  return x.dtype.base_dtype.name\n",
        "\n",
        "_EPSILON = 1e-7\n",
        "def epsilon():\n",
        "  return _EPSILON\n",
        "\n",
        "def _to_tensor(x, dtype):\n",
        "  return ops.convert_to_tensor(x, dtype=dtype)\n",
        "\n",
        "def binary_crossentropy(target, output, from_logits=False):\n",
        "  if not from_logits:\n",
        "    # transform back to logits\n",
        "   \n",
        "    #epsilon_ = tensorflow.convert_to_tensor(epsilon(), np.float32)\n",
        "    #output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
        "    output = math_ops.log(output / (1 - output))\n",
        "  return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDsoy0g8VlB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#del model\n",
        "def make_model_modified(dense_layer_sizes,filters, kernel_size,pool_size):\n",
        "\n",
        "    #dense_layer_sizes= 128\n",
        "    #filters = 20\n",
        "    #kernel_size = [3,3]\n",
        "    #pool_size = [2,2]\n",
        "    score_params = {\"sample_weight\": sample_weight_frame}\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', # my_score2(sample_weight = sample_weight_frame), <------------------- nie umiem zrobić by działał tutaj. Która funkcja? my_score czy my_scorer ?\n",
        "                  # co tu powinno wejść? o samo co do scoring w GridSearchCv? chyba nie: https://stackoverflow.com/questions/40572743/scikit-learn-grid-search-own-scoring-object-syntax\n",
        "                  # my_score2(sample_weight_frame) ---->  https://stackoverflow.com/questions/46858016/keras-custom-loss-function-to-pass-arguments-other-than-y-true-and-y-pred\n",
        "                  # my_loss ---------------------------->też nie chodzi a chyba powinien, coś z formatem nie tak.  ERROR: 'Tensor' object has no attribute 'values'\n",
        "                  # inne źródło: https://github.com/keras-team/keras/issues/2115\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17fUBh-ClyNT",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "## spr czemu się wykrzacza\n",
        "model = make_model_modified() #(128,20,3,2)\n",
        "hist = model.fit(X_train, y_train, epochs=15, batch_size=64, callbacks=[histories]) # validation_data=(X_val, y_val), class_weight = class_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmUkJOKTM_Wo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def larger_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(20, (3,3), input_shape=(1, 60, 87), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  #model.compile(loss=roc_auc_score_loss, optimizer='adam', metrics=['accuracy','mae'])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YQJvxfSN1Iy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "my_classifier = KerasClassifier(make_model_modified)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [128],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [8],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     # 'class_weight': [{ 0:0.02, 1:0.98}],  <------------------------------- może w ten sposób? Ale t też tylko w grid searchu\n",
        "                                     'batch_size': [32, 64]}, \n",
        "                         scoring=my_scorer, n_jobs=1, refit=True, cv=2)  ## SCORING ZMIENIONY na my_scorer (inne, np: 'roc_auc')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC9TynBWTR0E",
        "colab_type": "code",
        "outputId": "04c528c2-5396-4501-a1d9-c99d7bfb2c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1505
        }
      },
      "cell_type": "code",
      "source": [
        "histories = Histories()\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "print(class_weights)\n",
        "\n",
        "y_frame = pd.DataFrame(y_train, index=index)\n",
        "grid_result = validator.fit(X_train, y_frame) #, class_weight = class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.50930984 27.35330948]\n",
            "Epoch 1/8\n",
            "15290/15290 [==============================] - 11s 721us/step - loss: 0.1107 - acc: 0.9864\n",
            "Epoch 2/8\n",
            "15290/15290 [==============================] - 8s 513us/step - loss: 0.0690 - acc: 0.9885\n",
            "Epoch 3/8\n",
            "15290/15290 [==============================] - 8s 514us/step - loss: 0.0692 - acc: 0.9885\n",
            "Epoch 4/8\n",
            "15290/15290 [==============================] - 8s 507us/step - loss: 0.0679 - acc: 0.9886\n",
            "Epoch 5/8\n",
            "15290/15290 [==============================] - 8s 511us/step - loss: 0.0684 - acc: 0.9884\n",
            "Epoch 6/8\n",
            "15290/15290 [==============================] - 8s 502us/step - loss: 0.0670 - acc: 0.9885\n",
            "Epoch 7/8\n",
            "15290/15290 [==============================] - 8s 508us/step - loss: 0.0678 - acc: 0.9884\n",
            "Epoch 8/8\n",
            "15290/15290 [==============================] - 8s 511us/step - loss: 0.0676 - acc: 0.9886\n",
            "Epoch 1/8\n",
            "15291/15291 [==============================] - 11s 736us/step - loss: 0.1345 - acc: 0.9744\n",
            "Epoch 2/8\n",
            "15291/15291 [==============================] - 8s 517us/step - loss: 0.1200 - acc: 0.9750\n",
            "Epoch 3/8\n",
            "15291/15291 [==============================] - 8s 519us/step - loss: 0.1168 - acc: 0.9750\n",
            "Epoch 4/8\n",
            "15291/15291 [==============================] - 8s 519us/step - loss: 0.1185 - acc: 0.9750\n",
            "Epoch 5/8\n",
            "15291/15291 [==============================] - 8s 519us/step - loss: 0.1174 - acc: 0.9750\n",
            "Epoch 6/8\n",
            "15291/15291 [==============================] - 8s 519us/step - loss: 0.1181 - acc: 0.9750\n",
            "Epoch 7/8\n",
            "15291/15291 [==============================] - 8s 517us/step - loss: 0.1182 - acc: 0.9750\n",
            "Epoch 8/8\n",
            "15291/15291 [==============================] - 8s 517us/step - loss: 0.1169 - acc: 0.9750\n",
            "Epoch 1/8\n",
            "15290/15290 [==============================] - 9s 559us/step - loss: 0.0990 - acc: 0.9863\n",
            "Epoch 2/8\n",
            "15290/15290 [==============================] - 5s 324us/step - loss: 0.0684 - acc: 0.9885\n",
            "Epoch 3/8\n",
            "15290/15290 [==============================] - 5s 322us/step - loss: 0.0688 - acc: 0.9885\n",
            "Epoch 4/8\n",
            "15290/15290 [==============================] - 5s 319us/step - loss: 0.0676 - acc: 0.9885\n",
            "Epoch 5/8\n",
            "15290/15290 [==============================] - 5s 319us/step - loss: 0.0688 - acc: 0.9885\n",
            "Epoch 6/8\n",
            "15290/15290 [==============================] - 5s 316us/step - loss: 0.0672 - acc: 0.9885\n",
            "Epoch 7/8\n",
            "15290/15290 [==============================] - 5s 314us/step - loss: 0.0675 - acc: 0.9884\n",
            "Epoch 8/8\n",
            "15290/15290 [==============================] - 5s 313us/step - loss: 0.0658 - acc: 0.9885\n",
            "Epoch 1/8\n",
            "15291/15291 [==============================] - 9s 562us/step - loss: 0.1504 - acc: 0.9725\n",
            "Epoch 2/8\n",
            "15291/15291 [==============================] - 5s 323us/step - loss: 0.1207 - acc: 0.9750\n",
            "Epoch 3/8\n",
            "15291/15291 [==============================] - 5s 318us/step - loss: 0.1194 - acc: 0.9750\n",
            "Epoch 4/8\n",
            "15291/15291 [==============================] - 5s 318us/step - loss: 0.1222 - acc: 0.9750\n",
            "Epoch 5/8\n",
            "15291/15291 [==============================] - 5s 318us/step - loss: 0.1205 - acc: 0.9750\n",
            "Epoch 6/8\n",
            "15291/15291 [==============================] - 5s 319us/step - loss: 0.1178 - acc: 0.9750\n",
            "Epoch 7/8\n",
            "15291/15291 [==============================] - 5s 318us/step - loss: 0.1181 - acc: 0.9750\n",
            "Epoch 8/8\n",
            "15291/15291 [==============================] - 5s 316us/step - loss: 0.1189 - acc: 0.9750\n",
            "Epoch 1/8\n",
            "30581/30581 [==============================] - 20s 640us/step - loss: 0.1054 - acc: 0.9808\n",
            "Epoch 2/8\n",
            "30581/30581 [==============================] - 16s 518us/step - loss: 0.0963 - acc: 0.9817\n",
            "Epoch 3/8\n",
            "30581/30581 [==============================] - 16s 517us/step - loss: 0.0961 - acc: 0.9817\n",
            "Epoch 4/8\n",
            "30581/30581 [==============================] - 16s 516us/step - loss: 0.0948 - acc: 0.9817\n",
            "Epoch 5/8\n",
            "30581/30581 [==============================] - 16s 519us/step - loss: 0.0936 - acc: 0.9817\n",
            "Epoch 6/8\n",
            "30581/30581 [==============================] - 16s 515us/step - loss: 0.0936 - acc: 0.9817\n",
            "Epoch 7/8\n",
            "30581/30581 [==============================] - 16s 514us/step - loss: 0.0937 - acc: 0.9818\n",
            "Epoch 8/8\n",
            "27648/30581 [==========================>...] - ETA: 1s - loss: 0.0915 - acc: 0.9822"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aOXKJUC-bjnb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}